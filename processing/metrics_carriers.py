"""
===========================================================
Traitement : Statistiques par compagnie a√©rienne
-----------------------------------------------------------
Calcule, pour chaque batch :
- Nombre total de vols par compagnie
- Nombre de vols annul√©s par compagnie
- Nombre de vols retard√©s par compagnie
Les r√©sultats sont destin√©s √† la collection `carriers`
de la base MongoDB `flights`.

Structure :
{
  "carrier": "WN",
  "total": 1200,
  "cancelled": 40,
  "delayed": 280
}

Chaque batch incr√©mente les compteurs existants.
===========================================================
"""

import dask.dataframe as dd
from core.logger import get_logger

logger = get_logger("MetricsCarriers")


def compute_metrics_carriers(ddf: dd.DataFrame) -> list:
    """
    Calcule les statistiques de vols par compagnie dans le batch.

    Args:
        ddf (dd.DataFrame): Batch de vols au format Dask DataFrame
                            avec la colonne 'UniqueCarrier'.

    Returns:
        list[dict]: Liste de documents pr√™ts pour MongoDB :
            [{"carrier": "WN", "total": X, "cancelled": Y, "delayed": Z}, ...]
    """
    try:
        # ==============================
        # V√©rification des colonnes
        # ==============================
        required_cols = {"UniqueCarrier", "Cancelled", "ArrDelay"}
        if not required_cols.issubset(ddf.columns):
            logger.error(f"‚ùå Colonnes manquantes dans le batch : {required_cols - set(ddf.columns)}")
            return []

        # ==============================
        # Total des vols par compagnie
        # ==============================
        total_ddf = (
            ddf.groupby("UniqueCarrier")
            .size()
            .reset_index()
            .rename(columns={0: "total"})
        )

        # ==============================
        # Vols annul√©s par compagnie
        # ==============================
        cancelled_ddf = (
            ddf[ddf["Cancelled"] == 1]
            .groupby("UniqueCarrier")
            .size()
            .reset_index()
            .rename(columns={0: "cancelled"})
        )

        # ==============================
        # Vols retard√©s par compagnie
        # ==============================
        delayed_ddf = (
            ddf[ddf["ArrDelay"] > 0]
            .groupby("UniqueCarrier")
            .size()
            .reset_index()
            .rename(columns={0: "delayed"})
        )

        # ==============================
        # Fusion des trois DataFrames
        # ==============================
        merged = total_ddf.merge(cancelled_ddf, on="UniqueCarrier", how="left")
        merged = merged.merge(delayed_ddf, on="UniqueCarrier", how="left")

        merged = merged.fillna(value={"cancelled": 0, "delayed": 0})

        # Conversion finale
        results = merged.compute().to_dict(orient="records")

        # Renommage des cl√©s pour MongoDB
        formatted_results = [
            {
                "carrier": r["UniqueCarrier"],
                "total": int(r["total"]),
                "cancelled": int(r["cancelled"]),
                "delayed": int(r["delayed"])
            }
            for r in results
        ]

        logger.info(f"üõ´ Statistiques calcul√©es pour {len(formatted_results)} compagnies.")
        return formatted_results

    except Exception as e:
        logger.error(f"‚ùå Erreur lors du calcul des statistiques compagnies : {e}")
        return []
